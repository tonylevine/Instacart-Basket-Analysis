{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc8e13e-b7fe-4c6f-b97d-94028b395a64",
   "metadata": {},
   "source": [
    "# 01. Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "478de904-4b2f-414b-b88a-b2b02a3fa60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# Define path\n",
    "path = r'/home/scruffy/anaconda_projects/Instacart Basket Analysis/'\n",
    "# Import data to dataframes\n",
    "df_ords = pd.read_csv(os.path.join(path, '02 Data', 'Prepared Data', 'orders_wrangled.csv'))\n",
    "# Import data to dataframe\n",
    "df_prods = pd.read_csv(os.path.join(path, '02 Data', 'Original Data', 'products.csv'))\n",
    "df_ords_prods = pd.read_csv(os.path.join(path, '02 Data', 'Original Data', 'orders_products_prior.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f8eff-15e3-4a72-8e43-69899a505964",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dups = df_prods[df_prods['product_id'].duplicated()]\n",
    "print(df_dups.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c94076e-d028-4672-97cd-b5b765e10657",
   "metadata": {},
   "source": [
    "# 02. Addressing mixed-type columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d616c5e-630a-4a65-960e-2488280e7c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mix\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "# Create test dataframe\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "# Created mixed-type column\n",
    "df_test['Mix'] = ['a', 'b', 1, True]\n",
    "\n",
    "# Check for mixed types\n",
    "for col in df_test.columns.tolist():\n",
    "  weird = (df_test[[col]].map(type) != df_test[[col]].iloc[0].apply(type)).any(axis = 1)\n",
    "  if len (df_test[weird]) > 0:\n",
    "    print (col)\n",
    "\n",
    "# Correct data type for df_test\n",
    "df_test['Mix'] = df_test['Mix'].astype('str')\n",
    "print(df_test['Mix'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483fd6d9-615d-45f7-8164-68870601d9e2",
   "metadata": {},
   "source": [
    "# 03. Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63f14f45-77e7-48c1-ba82-51b6724723bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id             0\n",
       "product_id           0\n",
       "add_to_cart_order    0\n",
       "reordered            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count total number of observations with null values in products.csv\n",
    "df_ords_prods.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47301248-7093-4aae-8ce9-0889409b53da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product_id product_name  aisle_id  department_id  prices\n",
      "33             34          NaN       121             14    12.2\n",
      "68             69          NaN        26              7    11.8\n",
      "115           116          NaN        93              3    10.8\n",
      "261           262          NaN       110             13    12.1\n",
      "525           525          NaN       109             11     1.2\n",
      "1511         1511          NaN        84             16    14.3\n",
      "1780         1780          NaN       126             11    12.3\n",
      "2240         2240          NaN        52              1    14.2\n",
      "2586         2586          NaN       104             13    12.4\n",
      "3159         3159          NaN       126             11    13.1\n",
      "3230         3230          NaN       120             16    14.4\n",
      "3736         3736          NaN        41              8    14.8\n",
      "4283         4283          NaN        77              7    14.4\n",
      "4790         4790          NaN        91             16    14.5\n",
      "38187       38183          NaN        39             12    20.9\n",
      "40444       40440          NaN       120             16    14.8\n"
     ]
    }
   ],
   "source": [
    "# Subset products.csv to only entries with missing product names\n",
    "df_prods_nan = df_prods[df_prods['product_name'].isnull()==True]\n",
    "print(df_prods_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "314226aa-fb6b-46e5-a41c-55be8a370e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset products.csv to exclude entries with missing product names\n",
    "df_prods_clean = df_prods[df_prods['product_name'].isnull()==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a044da0b-a75a-4fee-ac12-a85827092a21",
   "metadata": {},
   "source": [
    "# 04. Handling duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fb69a343-2e5c-4e4f-9452-9c513131e595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 4)\n",
      "(32434489, 4)\n"
     ]
    }
   ],
   "source": [
    "# Identify entries with identical values in every column\n",
    "df_dups = df_ords_prods[df_ords_prods.duplicated()]\n",
    "\n",
    "# Check shape of data before dropping duplicates\n",
    "print(df_dups.shape)\n",
    "\n",
    "# Drop duplicates\n",
    "ords_prods_no_dups = df_ords_prods.drop_duplicates()\n",
    "\n",
    "#Check shape of data after dropping duplicates\n",
    "print(ords_prods_no_dups.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056c156a-ff1b-48d0-bfd5-74196922928d",
   "metadata": {},
   "source": [
    "# 05. Task Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d6704a9-98cb-4a7f-bd74-f9d765b3a91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Unnamed: 0      order_id       user_id  order_number     order_dow  \\\n",
      "count  3.421083e+06  3.421083e+06  3.421083e+06  3.421083e+06  3.421083e+06   \n",
      "mean   1.710541e+06  1.710542e+06  1.029782e+05  1.715486e+01  2.776219e+00   \n",
      "std    9.875817e+05  9.875817e+05  5.953372e+04  1.773316e+01  2.046829e+00   \n",
      "min    0.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00   \n",
      "25%    8.552705e+05  8.552715e+05  5.139400e+04  5.000000e+00  1.000000e+00   \n",
      "50%    1.710541e+06  1.710542e+06  1.026890e+05  1.100000e+01  3.000000e+00   \n",
      "75%    2.565812e+06  2.565812e+06  1.543850e+05  2.300000e+01  5.000000e+00   \n",
      "max    3.421082e+06  3.421083e+06  2.062090e+05  1.000000e+02  6.000000e+00   \n",
      "\n",
      "       order_hour_of_day  days_since_prior_order  \n",
      "count       3.421083e+06            3.214874e+06  \n",
      "mean        1.345202e+01            1.111484e+01  \n",
      "std         4.226088e+00            9.206737e+00  \n",
      "min         0.000000e+00            0.000000e+00  \n",
      "25%         1.000000e+01            4.000000e+00  \n",
      "50%         1.300000e+01            7.000000e+00  \n",
      "75%         1.600000e+01            1.500000e+01  \n",
      "max         2.300000e+01            3.000000e+01  \n"
     ]
    }
   ],
   "source": [
    "print(df_ords.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05582c8-01a6-471e-b9f5-511723c46caf",
   "metadata": {},
   "source": [
    "## Descriptive stats for this dataframe look good. There seem to be fewer observations in the days_since_prior_order column than the others, but this is likely fine as obviously not all orders will have a prior order. We will examine this further when looking at missing values. Minimum and maximum values are all reasonable, although the fact that the maximum value for order_number is exactly 100 could indicate that this column is capped, which might also be reasonable as the vast majority of values are well below 100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5bad35-c747-4878-8415-ae5921a571b3",
   "metadata": {},
   "source": [
    "## We can see that the file was exported with the index. We don't need this so I will drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a528e791-ca89-48ac-aad1-8b6f9b541df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
      "0   2539329        1    prior             1          2                  8   \n",
      "1   2398795        1    prior             2          3                  7   \n",
      "2    473747        1    prior             3          3                 12   \n",
      "3   2254736        1    prior             4          4                  7   \n",
      "4    431534        1    prior             5          4                 15   \n",
      "\n",
      "   days_since_prior_order  \n",
      "0                     NaN  \n",
      "1                    15.0  \n",
      "2                    21.0  \n",
      "3                    29.0  \n",
      "4                    28.0  \n"
     ]
    }
   ],
   "source": [
    "# Drop redundant index column\n",
    "df_ords.drop(columns=['Unnamed: 0'], inplace = True)\n",
    "print(df_ords.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7dd361-ef22-457c-8cac-cd4a60b5b3d8",
   "metadata": {},
   "source": [
    "# 06. Task Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d7d6812-90e8-404a-a4d4-b6e8961dc009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify mixed-type columns\n",
    "for col in df_ords_prods.columns.tolist():\n",
    "  weird = (df_ords_prods[[col]].map(type) != df_ords_prods[[col]].iloc[0].apply(type)).any(axis = 1)\n",
    "  if len (df_ords_prods[weird]) > 0:\n",
    "    print (col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d3c3d7-ab70-4b56-b7cc-c36e20ef876f",
   "metadata": {},
   "source": [
    "## Found no mixed-type columns in orders_wrangled.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb67096-c074-47ca-ada0-87b606606b31",
   "metadata": {},
   "source": [
    "# 07. Task Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88080ba1-0630-4431-b5c5-4650a44ecc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                       0\n",
       "user_id                        0\n",
       "eval_set                       0\n",
       "order_number                   0\n",
       "order_dow                      0\n",
       "order_hour_of_day              0\n",
       "days_since_prior_order    206209\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify missing values in df_ords\n",
    "df_ords.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bc0a56-3f3b-4866-a184-bea186c5dade",
   "metadata": {},
   "source": [
    "## Found 206209 missing observations in the days_since_prior_order column. 206209 is also the exact value of the largest user_id number, which suggests that every one of these null values is the first order by each user. No other missing values found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba6b52-c51d-47c6-b573-22388a2f9e8c",
   "metadata": {},
   "source": [
    "# 08. Task Step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18fd1c17-14a2-4496-99ff-344e65e50921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
      "0   2539329        1    prior             1          2                  8   \n",
      "1   2398795        1    prior             2          3                  7   \n",
      "2    473747        1    prior             3          3                 12   \n",
      "3   2254736        1    prior             4          4                  7   \n",
      "4    431534        1    prior             5          4                 15   \n",
      "\n",
      "   days_since_prior_order  no_prior_orders  \n",
      "0                     NaN             True  \n",
      "1                    15.0            False  \n",
      "2                    21.0            False  \n",
      "3                    29.0            False  \n",
      "4                    28.0            False  \n"
     ]
    }
   ],
   "source": [
    "# Create flag column for missing days_since_prior_order\n",
    "df_ords['no_prior_orders'] = df_ords['days_since_prior_order'].isnull()==True\n",
    "print(df_ords.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02068a05-0c3b-4c8f-9804-635ad731d17b",
   "metadata": {},
   "source": [
    "## Created a flag column to identify rows with null values in days_since_prior_order because these rows should not be excluded from analysis just because the user has no prior orders. This allows us to avoid any potential errors that could result from null values while retaining all important data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464a21fc-541d-42ce-a060-58582c71828b",
   "metadata": {},
   "source": [
    "# 09. Task Step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12a2bb4c-85e5-4ca2-b678-8dbc98a75aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 8)\n"
     ]
    }
   ],
   "source": [
    "# Identify duplicated rows\n",
    "print(df_ords[df_ords.duplicated()].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb11f65-534b-43f0-a32e-0fc5f8af0bf4",
   "metadata": {},
   "source": [
    "## No duplicates found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d90fa811-62be-4205-8837-41e1b8fdd340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         product_id      aisle_id  department_id        prices\n",
      "count  49672.000000  49672.000000   49672.000000  49672.000000\n",
      "mean   24850.349775     67.762442      11.728942      9.993282\n",
      "std    14340.705287     38.315784       5.850779    453.615536\n",
      "min        1.000000      1.000000       1.000000      1.000000\n",
      "25%    12432.750000     35.000000       7.000000      4.100000\n",
      "50%    24850.500000     69.000000      13.000000      7.100000\n",
      "75%    37268.250000    100.000000      17.000000     11.100000\n",
      "max    49688.000000    134.000000      21.000000  99999.000000\n"
     ]
    }
   ],
   "source": [
    "print(df_prods_clean_no_dups.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3cd4b78-2a92-4d86-9f69-897f28af03ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product_id                      product_name  aisle_id  department_id  \\\n",
      "33666       33664             2 % Reduced Fat  Milk        84             16   \n",
      "21554       21553  Lowfat 2% Milkfat Cottage Cheese       108             16   \n",
      "19392       19391         Turkey Breast Tenderloins        49             12   \n",
      "25580       25579     Naturally Smoked Trout Fillet        15             12   \n",
      "40490       40486                   Chicken Tenders        49             12   \n",
      "21468       21467            Wild Caught Raw Shrimp        15             12   \n",
      "9020         9020  Boneless Skinless Chicken Thighs        35             12   \n",
      "9896         9896    Uncured Applewood Smoked Bacon       106             12   \n",
      "14207       14207                  Angus Roast Beef         7             12   \n",
      "41097       41093          Sugar Free Dry Rub Bacon       106             12   \n",
      "39050       39046           Smok Cured Turkey Bacon       106             12   \n",
      "36577       36573                    Peppered Bacon       106             12   \n",
      "48343       48339                     Lobster Tails        39             12   \n",
      "26078       26077                 Cocktail Sausages       106             12   \n",
      "19548       19547                 Beef Frankfurters       106             12   \n",
      "9302         9302        Thin Sliced Chicken Breast        35             12   \n",
      "22193       22192                  Lite Beef Franks       106             12   \n",
      "33987       33985                  Sausage, Chorizo       106             12   \n",
      "38752       38748                   Polish Kielbasa       106             12   \n",
      "10814       10814            Applewood Smoked Bacon       106             12   \n",
      "\n",
      "        prices  \n",
      "33666  99999.0  \n",
      "21554  14900.0  \n",
      "19392     25.0  \n",
      "25580     25.0  \n",
      "40490     25.0  \n",
      "21468     25.0  \n",
      "9020      25.0  \n",
      "9896      24.9  \n",
      "14207     24.9  \n",
      "41097     24.9  \n",
      "39050     24.9  \n",
      "36577     24.9  \n",
      "48343     24.9  \n",
      "26078     24.8  \n",
      "19548     24.8  \n",
      "9302      24.8  \n",
      "22193     24.8  \n",
      "33987     24.8  \n",
      "38752     24.7  \n",
      "10814     24.7  \n"
     ]
    }
   ],
   "source": [
    "df_prods_sorted = df_prods_clean_no_dups.sort_values(by='prices', ascending=False)\n",
    "print(df_prods_sorted.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c22bed0a-fab0-43c1-9edc-85a781b052fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         product_id      aisle_id  department_id        prices\n",
      "count  49672.000000  49672.000000   49672.000000  49670.000000\n",
      "mean   24850.349775     67.762442      11.728942      7.680437\n",
      "std    14340.705287     38.315784       5.850779      4.199381\n",
      "min        1.000000      1.000000       1.000000      1.000000\n",
      "25%    12432.750000     35.000000       7.000000      4.100000\n",
      "50%    24850.500000     69.000000      13.000000      7.100000\n",
      "75%    37268.250000    100.000000      17.000000     11.100000\n",
      "max    49688.000000    134.000000      21.000000     25.000000\n"
     ]
    }
   ],
   "source": [
    "df_prods_clean_no_dups.loc[df_prods_clean_no_dups['prices'] >100, 'prices'] = np.nan\n",
    "print(df_prods_clean_no_dups.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "954012aa-69e4-4226-b456-f3164094823b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49672, 5)\n",
      "(3421083, 8)\n"
     ]
    }
   ],
   "source": [
    "print(df_prods_clean_no_dups.shape)\n",
    "print(df_ords.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4271e7-3067-4a00-827c-f11268047a8b",
   "metadata": {},
   "source": [
    "# 10. Task Step 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afb4901f-3cf5-46be-bb2c-d19ed49ed596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data\n",
    "#df_ords.to_csv(os.path.join(path, '02 Data','Prepared Data', 'orders_checked.csv'), index=False)\n",
    "#df_prods_clean_no_dups.to_csv(os.path.join(path, '02 Data','Prepared Data', 'products_checked_corrected.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
